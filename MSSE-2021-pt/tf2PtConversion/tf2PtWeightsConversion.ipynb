{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 1.x to PyTorch conversion\n",
    "\n",
    "This is an experimental notebook to convert CHAP models from Tensorflow 1.x to PyTorch.\n",
    "The notebooks is tested with the below package versions.\n",
    "\n",
    "```\n",
    "python 3.7.10\n",
    "tensorflow 1.15\n",
    "torch 1.13.1\n",
    "onnx 1.14.1\n",
    "tf2onnx 1.16.1\n",
    "onnx2pytorch 0.4.1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/animeshtuf/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import logging\n",
    "\n",
    "import tensorflow\n",
    "if int(tensorflow.__version__.split(\".\")[0]) >= 2:\n",
    "    import tensorflow.compat.v1 as tf\n",
    "else:\n",
    "    import tensorflow as tf\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "import pickle\n",
    "\n",
    "from model import CNNBiLSTMModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import onnx\n",
    "from onnx2pytorch import ConvertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tensorflow weights and save them as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_20304/2207592410.py:4: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_20304/2207592410.py:4: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_20304/2207592410.py:6: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_20304/2207592410.py:6: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_20304/2207592410.py:6: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_20304/2207592410.py:6: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_20304/2207592410.py:7: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 22:15:51.830831: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2024-07-22 22:15:51.834631: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2918400000 Hz\n",
      "2024-07-22 22:15:51.835006: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5c87b95223b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-22 22:15:51.835019: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-07-22 22:15:51.835145: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-07-22 22:15:51.835152: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-07-22 22:15:51.835160: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (animeshtuf): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /tmp/ipykernel_20304/2207592410.py:7: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../pre-trained-models/CHAP_ALL_ADULTS/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../pre-trained-models/CHAP_ALL_ADULTS/variables/variables\n"
     ]
    }
   ],
   "source": [
    "tf_weights_path = \"../pre-trained-models/CHAP_ALL_ADULTS\"\n",
    "tf_weights_pickle_path = \"./pretrained_model_weights/CHAP_ALL_ADULTS.pickle\"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "p = max(1, multiprocessing.cpu_count()//2)\n",
    "sess = tf.Session(config=tf.ConfigProto(inter_op_parallelism_threads=p, intra_op_parallelism_threads=p))\n",
    "tf.saved_model.loader.load(sess, [\"serve\"], tf_weights_path)\n",
    "\n",
    "vars = sess.graph.get_collection('trainable_variables')\n",
    "weights = {}\n",
    "for v in vars:\n",
    "    weights[v.name] = sess.run(v)  # retrieve the value from the tf backend\n",
    "weights_list = [(k, v) for k, v in weights.items()]\n",
    "with open(tf_weights_pickle_path, 'wb') as handle:\n",
    "    pickle.dump(weights_list, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert existing Tensorflow model to ONNX model\n",
    "\n",
    "`tf2onnx` also supports Python based API however the command line produces the most consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/animeshtuf/anaconda3/envs/deep_postures/lib/python3.7/runpy.py:125: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "WARNING:tensorflow:From /home/animeshtuf/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tf2onnx/verbose_logging.py:76: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "2024-07-22 22:15:53,020 - WARNING - From /home/animeshtuf/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tf2onnx/verbose_logging.py:76: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "2024-07-22 22:15:53.021138: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-07-22 22:15:53,026 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2024-07-22 22:15:53,026 - WARNING - '--signature_def' not provided. Using all signatures.\n",
      "2024-07-22 22:15:53,609 - INFO - Using tensorflow=1.15.0, onnx=1.14.1, tf2onnx=1.16.1/15c810\n",
      "2024-07-22 22:15:53,610 - INFO - Using opset <onnx, 15>\n",
      "2024-07-22 22:15:53,787 - INFO - Computed 29 values for constant folding\n",
      "2024-07-22 22:15:53,864 - INFO - folding node using tf type=Identity, name=model/conv2d/kernel/read\n",
      "2024-07-22 22:15:53,865 - INFO - folding node using tf type=Identity, name=model/conv2d/bias/read\n",
      "2024-07-22 22:15:53,865 - INFO - folding node using tf type=Identity, name=model/conv2d_1/kernel/read\n",
      "2024-07-22 22:15:53,865 - INFO - folding node using tf type=Identity, name=model/conv2d_1/bias/read\n",
      "2024-07-22 22:15:53,865 - INFO - folding node using tf type=Identity, name=model/conv2d_2/kernel/read\n",
      "2024-07-22 22:15:53,865 - INFO - folding node using tf type=Identity, name=model/conv2d_2/bias/read\n",
      "2024-07-22 22:15:53,865 - INFO - folding node using tf type=Identity, name=model/conv2d_3/kernel/read\n",
      "2024-07-22 22:15:53,866 - INFO - folding node using tf type=Identity, name=model/conv2d_3/bias/read\n",
      "2024-07-22 22:15:53,866 - INFO - folding node using tf type=Identity, name=model/conv2d_4/kernel/read\n",
      "2024-07-22 22:15:53,867 - INFO - folding node using tf type=Identity, name=model/conv2d_4/bias/read\n",
      "2024-07-22 22:15:53,867 - INFO - folding node using tf type=Identity, name=model/dense/kernel/read\n",
      "2024-07-22 22:15:53,869 - INFO - folding node using tf type=Identity, name=model/dense/bias/read\n",
      "2024-07-22 22:15:53,869 - INFO - folding node using tf type=ConcatV2, name=bidirectional_rnn/fw/fw/concat\n",
      "2024-07-22 22:15:53,869 - INFO - folding node using tf type=StridedSlice, name=bidirectional_rnn/fw/fw/strided_slice_1\n",
      "2024-07-22 22:15:53,870 - INFO - folding node using tf type=Range, name=bidirectional_rnn/fw/fw/TensorArrayUnstack/range\n",
      "2024-07-22 22:15:53,870 - INFO - folding node using tf type=Minimum, name=bidirectional_rnn/fw/fw/Minimum\n",
      "2024-07-22 22:15:53,870 - INFO - folding node using tf type=Identity, name=bidirectional_rnn/fw/lstm_cell/kernel/read\n",
      "2024-07-22 22:15:53,870 - INFO - folding node using tf type=Identity, name=bidirectional_rnn/fw/lstm_cell/bias/read\n",
      "2024-07-22 22:15:53,870 - INFO - folding node using tf type=ConcatV2, name=bidirectional_rnn/fw/fw/concat_2\n",
      "2024-07-22 22:15:53,870 - INFO - folding node using tf type=ConcatV2, name=bidirectional_rnn/bw/bw/concat\n",
      "2024-07-22 22:15:53,870 - INFO - folding node using tf type=StridedSlice, name=bidirectional_rnn/bw/bw/strided_slice_1\n",
      "2024-07-22 22:15:53,870 - INFO - folding node using tf type=Range, name=bidirectional_rnn/bw/bw/TensorArrayUnstack/range\n",
      "2024-07-22 22:15:53,870 - INFO - folding node using tf type=Minimum, name=bidirectional_rnn/bw/bw/Minimum\n",
      "2024-07-22 22:15:53,871 - INFO - folding node using tf type=Identity, name=bidirectional_rnn/bw/lstm_cell/kernel/read\n",
      "2024-07-22 22:15:53,871 - INFO - folding node using tf type=Identity, name=bidirectional_rnn/bw/lstm_cell/bias/read\n",
      "2024-07-22 22:15:53,871 - INFO - folding node using tf type=ConcatV2, name=bidirectional_rnn/bw/bw/concat_2\n",
      "2024-07-22 22:15:53,871 - INFO - folding node using tf type=Identity, name=dense/bias/read\n",
      "2024-07-22 22:15:53,871 - INFO - folding node using tf type=ConcatV2, name=dense/Tensordot/concat\n",
      "2024-07-22 22:15:53,871 - INFO - folding node using tf type=Reshape, name=dense/Tensordot/Reshape_1\n",
      "2024-07-22 22:15:53,873 - INFO - folding node type=Range, name=bidirectional_rnn/fw/fw/range\n",
      "2024-07-22 22:15:53,873 - INFO - folding node type=Range, name=bidirectional_rnn/fw/fw/range_1\n",
      "2024-07-22 22:15:53,874 - INFO - folding node type=Range, name=bidirectional_rnn/bw/bw/range\n",
      "2024-07-22 22:15:53,874 - INFO - folding node type=Range, name=bidirectional_rnn/bw/bw/range_1\n",
      "2024-07-22 22:15:53,943 - INFO - Optimizing ONNX model\n",
      "2024-07-22 22:15:54,154 - INFO - After optimization: Cast -9 (16->7), Concat -3 (9->6), Const -53 (83->30), Expand -2 (4->2), Gather +2 (2->4), Identity -2 (2->0), Reshape -3 (9->6), Squeeze -2 (4->2), Transpose -14 (16->2), Unsqueeze -6 (10->4)\n",
      "2024-07-22 22:15:54,171 - INFO - \n",
      "2024-07-22 22:15:54,172 - INFO - Successfully converted TensorFlow model ../pre-trained-models/CHAP_ALL_ADULTS to ONNX\n",
      "2024-07-22 22:15:54,172 - INFO - Model inputs: ['input']\n",
      "2024-07-22 22:15:54,172 - INFO - Model outputs: ['output']\n",
      "2024-07-22 22:15:54,172 - INFO - ONNX model is saved at ./onnx_models/CHAP_ALL_ADULTS.onnx\n"
     ]
    }
   ],
   "source": [
    "!python -m tf2onnx.convert --saved-model ../pre-trained-models/CHAP_ALL_ADULTS --output ./onnx_models/CHAP_ALL_ADULTS.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to PyTorch weights\n",
    "\n",
    "We will be manually loading the weights into the PyTorch layers. For the LSTM layers we will be using the model weights from the ONNX converted model and for all the other layers we will be using the weights from the pickle file we created earlier. We are not using just the ONNX converted model as it creates complex layers for the convolution layer and also has a limitation of having a batch size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying layer model/conv2d/kernel:0 to cnn_model.conv1.weight\n",
      "Copying layer model/conv2d/bias:0 to cnn_model.conv1.bias\n",
      "Copying layer model/conv2d_1/kernel:0 to cnn_model.conv2.weight\n",
      "Copying layer model/conv2d_1/bias:0 to cnn_model.conv2.bias\n",
      "Copying layer model/conv2d_2/kernel:0 to cnn_model.conv3.weight\n",
      "Copying layer model/conv2d_2/bias:0 to cnn_model.conv3.bias\n",
      "Copying layer model/conv2d_3/kernel:0 to cnn_model.conv4.weight\n",
      "Copying layer model/conv2d_3/bias:0 to cnn_model.conv4.bias\n",
      "Copying layer model/conv2d_4/kernel:0 to cnn_model.conv5.weight\n",
      "Copying layer model/conv2d_4/bias:0 to cnn_model.conv5.bias\n",
      "Copying layer model/dense/kernel:0 to cnn_model.fc.weight\n",
      "Copying layer model/dense/bias:0 to cnn_model.fc.bias\n",
      "Copying layer dense/kernel:0 to fc_bilstm.weight\n",
      "Copying layer dense/bias:0 to fc_bilstm.bias\n",
      "Automatic inference of operator: round\n",
      "Copying layer LSTM_LSTM__84:0.lstm.weight_ih_l0 to bil_lstm.weight_ih_l0\n",
      "Copying layer LSTM_LSTM__84:0.lstm.weight_hh_l0 to bil_lstm.weight_hh_l0\n",
      "Copying layer LSTM_LSTM__84:0.lstm.bias_ih_l0 to bil_lstm.bias_ih_l0\n",
      "Copying layer LSTM_LSTM__84:0.lstm.bias_hh_l0 to bil_lstm.bias_hh_l0\n",
      "Copying layer LSTM_LSTM__84:0.lstm.weight_ih_l0_reverse to bil_lstm.weight_ih_l0_reverse\n",
      "Copying layer LSTM_LSTM__84:0.lstm.weight_hh_l0_reverse to bil_lstm.weight_hh_l0_reverse\n",
      "Copying layer LSTM_LSTM__84:0.lstm.bias_ih_l0_reverse to bil_lstm.bias_ih_l0_reverse\n",
      "Copying layer LSTM_LSTM__84:0.lstm.bias_hh_l0_reverse to bil_lstm.bias_hh_l0_reverse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/animeshtuf/anaconda3/envs/deep_postures/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n",
      "/home/animeshtuf/anaconda3/envs/deep_postures/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "onnx_model_path = \"./onnx_models/CHAP_ALL_ADULTS.onnx\"\n",
    "\n",
    "# Open the pickle file for reading in binary mode\n",
    "with open(tf_weights_pickle_path, 'rb') as f:\n",
    "    # Load the data from the pickle file\n",
    "    weights_list = pickle.load(f)\n",
    "\n",
    "# Model Configurations\n",
    "amp_factor =2\n",
    "bi_lstm_window_size = 42\n",
    "num_classes = 2\n",
    "model = CNNBiLSTMModel(amp_factor=amp_factor, bi_lstm_win_size=bi_lstm_window_size, num_classes=2, load_pretrained = True)\n",
    "\n",
    "# Copy layers other than LSTM\n",
    "with torch.no_grad():\n",
    "      pt_model_params = list(model.named_parameters())\n",
    "      n_tf = 0\n",
    "      n_pt = 0\n",
    "      while n_tf<len(weights_list):\n",
    "            pt_name, pt_param = pt_model_params[n_pt]\n",
    "            tf_name, tf_param = weights_list[n_tf]\n",
    "            if \"lstm\" in tf_name:\n",
    "                  n_pt=n_pt+4\n",
    "                  n_tf=n_tf+2\n",
    "                  continue\n",
    "            # conv weights are in order NHWC for TF and NCHW for PyTorch\n",
    "            if \"conv\" in tf_name and len(tf_param.shape) == 4:\n",
    "                  tf_param = np.transpose(tf_param, (3, 2, 0, 1)).copy()  \n",
    "            # dense weights are in order KN for TF and NK for PyTorch\n",
    "            elif \"dense\" in tf_name and len(tf_param.shape) == 2:\n",
    "                  tf_param = np.transpose(tf_param).copy()\n",
    "            n_tf+=1\n",
    "            n_pt+=1\n",
    "                  \n",
    "            if not tf_param.shape == pt_param.detach().numpy().shape:\n",
    "                  print(\"Shape error\", \"TF\", tf_name, tf_param.shape, \"\\tPT\", pt_name, pt_param.detach().numpy().shape)\n",
    "            print(f\"Copying layer {tf_name} to {pt_name}\")      \n",
    "            pt_param.copy_(torch.tensor(tf_param, requires_grad=True, dtype=pt_param.dtype))\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "pytorch_onnx_model = ConvertModel(onnx_model)\n",
    "\n",
    "# Get the model's state_dict\n",
    "model_weights = pytorch_onnx_model.state_dict()\n",
    "lstm_weights = {}\n",
    "for k in model_weights:\n",
    "    if \"lstm\" in k.lower() and 'LSTMCellZeroState' not in k:\n",
    "        lstm_weights[k] = model_weights[k]\n",
    "\n",
    "lstm_tuple_list = [(k,v) for k,v in lstm_weights.items()]\n",
    "\n",
    "with torch.no_grad():\n",
    "      pt_model_params = list(model.named_parameters())\n",
    "      n_onx = 0\n",
    "      n_pt = 0\n",
    "      while n_pt<len(pt_model_params) and n_onx<len(lstm_tuple_list):\n",
    "            pt_name, pt_param = pt_model_params[n_pt]\n",
    "            onx_name, onx_param = lstm_tuple_list[n_onx]\n",
    "            if 'lstm' not in pt_name.lower():\n",
    "                  n_pt+=1\n",
    "                  continue\n",
    "                  \n",
    "            if not onx_param.shape == pt_param.detach().numpy().shape:\n",
    "                  print(\"Shape error\", \"ONX\", onx_param, onx_param.shape, \"\\tPT\", pt_name, pt_param.detach().numpy().shape)\n",
    "            print(f\"Copying layer {onx_name} to {pt_name}\")\n",
    "            pt_param.copy_(torch.tensor(onx_param, requires_grad=True, dtype=pt_param.dtype))\n",
    "            n_pt+=1\n",
    "            n_onx+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model_save_path = \"../pre-trained-models-pt/\"\n",
    "torch.save(model.state_dict(), os.path.join(pytorch_model_save_path, \"CHAP_ALL_ADULTS.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_postures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
